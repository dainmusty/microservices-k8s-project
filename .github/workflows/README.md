.github/
  workflows/
    infra-deploy.yml
    bootstrap-argocd.yml
    api-ci.yml
    reusable/
        terraform.yml
        docker-build.yml
        update-manifest.yml

terraform/
  vpc/
  eks/
  argocd/
  alb/
  monitoring/

k8s/
  bootstrap/
    root-application.yaml
  apps/
    dev/
      api/
        deployment.yaml
        service.yaml
      web/
      payment/

OPTIONAL NEXT IMPROVEMENTS bootstrap argocd

We can add:

ğŸ”¹ Automatic cluster drift detection

ArgoCD CLI + notification when apps are OutOfSync

ğŸ”¹ Slack / MS Teams notification on rollout
ğŸ”¹ Auto-create ArgoCD Projects per environment
ğŸ”¹ Add SOPS / Sealed Secrets auto-sync


FINAL BEST PRACTICE WORKFLOW MODEL

Your repo should have 3 workflows:

1ï¸âƒ£ INFRA WORKFLOW (infra-ci.yml)

Triggers when Terraform files change.

Responsibilities:

Terraform plan

Terraform apply

Install EKS + addons

Install ArgoCD (Terraform Helm)

Extract outputs if needed

No Kubernetes manifest is applied here.

2ï¸âƒ£ ARGO BOOTSTRAP WORKFLOW (bootstrap-argocd.yml)

(This is the workflow you showed.)

Triggers when:

k8s/bootstrap/** changes

Manually (workflow_dispatch)

Responsibilities:

Apply root-app.yaml

Ensure sync policy is applied

3ï¸âƒ£ APP IMAGE CI/CD WORKFLOW (api-ci.yml, web-ci.yml)

Triggers when:

docker/api/**
src/api/**


Responsibilities:

Build Docker image

Trivy scan

Push to ECR

Patch manifest (image tag)

Commit back to Git

ArgoCD then:

sees updated manifest

deploys automatically

ğŸŸ© So, which workflow should â€œrun firstâ€?

Yes â€” the moment you run terraform apply, and the cluster + ArgoCD installs:

âœ” ArgoCD bootstrap workflow comes next

(Manually, or automatically if bootstrap files changed)

âœ” Then app CI pipelines run whenever code or Dockerfiles change
ğŸŸ¢ Final Recommendation

ğŸ‘‰ KEEP your new ArgoCD bootstrap workflow
ğŸ‘‰ REMOVE all Argo logic from Terraform workflow
ğŸ‘‰ Do not push commits from CI to trigger Argo sync
ğŸ‘‰ Let ArgoCD manage deployments
ğŸ‘‰ Let CI only update manifests + update images in ECR

âœ… High-Level Principle

Manifests should NEVER contain images until CI/CD has built, scanned, and pushed the final image to ECR.

â›” Developers should NOT hand you an image tag.
â›” You should NOT put an image that was not scanned into Kubernetes manifests.
â›” You do NOT manually prepare manifests with pre-existing images.

âœ” Instead, CI/CD is the source of trust.

ğŸ¯ Correct GitOps Flow (Industry Best Practice)
1ï¸âƒ£ Developers push code â†’ GitHub

This triggers your CI pipeline.

2ï¸âƒ£ GitHub Actions builds the Docker image
docker build -t app:commit_sha .

3ï¸âƒ£ CI scans the Docker image (Trivy / Aqua / Grype)

If the image has CRITICAL vulnerabilities â†’ FAIL

trivy image app:commit_sha

4ï¸âƒ£ If the scan passes â†’ CI pushes image â†’ ECR
docker tag app:commit_sha ACCOUNT.dkr.ecr.../app:commit_sha
docker push ACCOUNT.dkr.ecr.../app:commit_sha

5ï¸âƒ£ CI updates manifest (Helm values.yaml or k8s Deployment.yaml)

CI updates ONLY the image tag:

image:
  repository: ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/app
  tag: commit_sha

6ï¸âƒ£ ArgoCD syncs and deploys

ArgoCD picks up the updated Git commit and deploys the new image.

âŒ What you should NOT do

You should NOT take developer images manually and:

scan them in your infra repo

push them yourself

add them manually into manifest files

That breaks the entire purpose of CI/CD & GitOps.

ğŸ”¥ Final Answer
âœ” YES â€” the pipeline MUST do this:
Stage	Should Happen?	Who does it?
Build image	âœ” required	GitHub Actions
Scan image (Trivy)	âœ” mandatory	GitHub Actions
Push to ECR	âœ” mandatory	GitHub Actions
Update manifest (tag only)	âœ” GitOps update	GitHub Actions (or Argo Image Updater)
Argo deploys it	âœ”	ArgoCD
âŒ NO â€” you should not manually place unsafe images directly into manifests.
ğŸ“Œ If the dev team already â€œfinished the imagesâ€

Even if developers build images locally:

You must still rebuild, rescan, retag, and push via CI/CD.

Why?

Local environment â‰  trusted environment

No vulnerability scan = unsafe

No SBOM

No provenance

No reproducibility

CI/CD provides these guarantees.

.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ infra.yml                  # Terraform apply -> EKS + addons + argocd bootstrap
â”‚       â””â”€â”€ build-and-push.yml         # Build â†’ Trivy â†’ Push to ECR â†’ update manifests (app repo)
â”œâ”€â”€ infra/                             # Terraform infra repo (EKS, ECR, roles, argocd helm)
â”‚   â”œâ”€â”€ modules/
â”‚   â””â”€â”€ env/
â”œâ”€â”€ k8s/                               
â”‚   â”œâ”€â”€ bootstrap/                      # argocd bootstrap (App-of-Apps)
â”‚   â”‚   â””â”€â”€ argocd-bootstrap.yaml
â”‚   â””â”€â”€ apps/
â”‚       â””â”€â”€ dev/
â”‚           â””â”€â”€ my-app/                 # example app (helm or manifests)
â”‚               â”œâ”€â”€ Chart.yaml
â”‚               â”œâ”€â”€ values.yaml
â”‚               â””â”€â”€ templates/
â”œâ”€â”€ .README.md

hat does this mean?
paths:
      - "docker/api/**"
      - ".github/workflows/api-ci.yml"

2. Expected GitOps Flow (What You Described Is Correct)
âœ” Developer edits code
âœ” Developer updates Dockerfile
âœ” Pipeline triggers automatically
âœ” New image is built
âœ” Image scanned (Trivy)
âœ” Image pushed to ECR
âœ” CI pipeline updates the Kubernetes manifest (patches image tag)
âœ” Git pushes updated manifest to GitOps repo
âœ” ArgoCD detects Git change
âœ” ArgoCD automatically syncs the cluster

Think of it like this
Dockerfile

â†’ Defines how to build the application container.

GitHub Actions CI

â†’ Builds image â†’ Scans â†’ Pushes â†’ Updates Kubernetes manifest.

Kubernetes manifest (deployment.yaml)

â†’ Defines which image version should run.

ArgoCD

â†’ Applies the manifest to the EKS cluster.

ğŸ›  Example: Patch manifest inside CI

Letâ€™s say your manifest file is:

k8s/apps/dev/api/deployment.yaml

Your CI pipeline will run something like:

yq e '.spec.template.spec.containers[0].image = env(NEW_IMAGE)' -i k8s/apps/dev/api/deployment.yaml


Then commit + push:

git add k8s/apps/dev/api/deployment.yaml
git commit -m "Update API image to $NEW_IMAGE"
git push


ArgoCD sees this commit â†’ sync â†’ deploy.

âœ” Final Answer:
CI updates the manifest by editing the YAML file directly â€” NOT the Dockerfile.

The Dockerfile is only used for building the container image.
The manifest is updated by the pipeline after the image is pushed to ECR.

Why This Works (GitOps Fundamentals)

CIâ€™s responsibility:

Build

Scan

Push to ECR

Patch manifest

Commit back to repo

ArgoCDâ€™s responsibility:

Monitor Git repo

Deploy EVERYTHING it finds inside its watched folders

Keep cluster in sync

They are independent stages.

so right i have a couple things to do. first of i, i will like to automate everything by just doing terraform apply. the way i see it, am gonna a long workflow with lots of jobs. what is best practice? i first need to deploy the infra via terraform. 2. then i deploy my app via argocd. are we allowed to have multiple workflow files and reuse them or call them once infra is ready or something?
ChatGPT said:

Great question â€” and yes, you can (and should) split your Terraform + GitOps/ArgoCD workflows into multiple GitHub Actions pipelines. Thatâ€™s the cleanest, safest, most maintainable design.

Below is the best-practice architecture for fully automated infra + GitOps CD with GitHub Actions, Terraform, ArgoCD, and microservices (API/web/payment/etc).

âœ… Best Practice: Multiple Workflows, Each With a Single Responsibility

You should NOT put everything into one long workflow.
Instead, break it into 3 layers, each responsible for one thing:

1ï¸âƒ£ Infrastructure Workflow â€” infra-deploy.yml

Triggered manually or when infra code changes.

Purpose:

terraform init/plan/apply

Deploy EKS, VPC, ALB, EBS CSI, IAM roles, Secrets Manager, etc.

Install system-level components via Helm (ALB Controller, EBS, Prometheus, Grafana, ArgoCD bootstrap app)

ğŸ‘‰ This workflow runs once when provisioning or updating infrastructure.

2ï¸âƒ£ GitOps Bootstrap Workflow â€” bootstrap-argocd.yml

Triggered only once when setting up GitOps or when you change ArgoCD root apps.

Purpose:

Apply ArgoCD bootstrap Application (App of Apps)

Sync ArgoCD automatically

This ensures:

/k8s/bootstrap is deployed (root)

Root deploys /k8s/apps/dev/*

ArgoCD now watches Git forever

ğŸ‘‰ After this, you NEVER manually kubectl apply again â€” Argo takes over.

3ï¸âƒ£ App CI Workflow â€” api-ci.yml, web-ci.yml

Triggered on push to a microservice folder.

Purpose:

Build container image

Scan (Trivy)

Push to GitHub/AWS ECR

Patch ONLY the manifest for that app
(e.g. k8s/apps/dev/api/deployment.yaml)

ArgoCD sees the change â†’ auto deploys

This is your continuous deployment workflow.

ğŸ” How They Work Together
STEP 1 â€” Deploy Infrastructure

You run:

terraform apply


GitHub Actions â†’ infra-deploy.yml
EKS + ArgoCD + ALB + EBS + Monitoring â†’ configured.

STEP 2 â€” Bootstrap ArgoCD

GitHub Actions deploys:

k8s/bootstrap/argocd-root-application


ArgoCD now pulls:

k8s/apps/dev/api
k8s/apps/dev/web
k8s/apps/dev/payment

STEP 3 â€” API CI/CD Workflow

The API developer pushes to apps/api/:

Docker image built & pushed

Deployment.yaml patched

ArgoCD auto-sync picks it up

App redeployed in seconds

ğŸ§© Are We Allowed to Reuse Workflows? YES.

GitHub Actions supports:

workflow_call: re-usable workflows

jobs.<job>.uses: calling another workflow

workflow dispatch

Best practice:

Infra
infra-deploy.yml â†’ reusable terraform-workflow.yml

Apps

Each microservice has its own small CI:

api-ci.yml â†’ reusable build-and-push.yml


This keeps everything DRY and modular.

ğŸ”¥ Recommended Folder Structure
.github/workflows/
    infra-deploy.yml
    bootstrap-argocd.yml
    api-ci.yml
    web-ci.yml
    reusable/
        terraform.yml
        docker-ci.yml

terraform/
    vpc/
    eks/
    alb/
    argocd/
    monitoring/

k8s/
    bootstrap/
        root-application.yaml
    apps/
        dev/
            api/
                deployment.yaml
                service.yaml
            web/
            payment/

ğŸ§  To Your Specific Question

does Argo automatically deploy the apps for the first time even with only one file (deployment.yaml) being updated?

âœ… Yes, ArgoCD will deploy the entire app for the first time even if you change only one file

because:

ArgoCD watches the entire folder (e.g. /k8s/apps/dev/api)

On the first sync, Argo applies ALL manifests in that folder

The CI workflow only needs to update one file (deployment.yaml)
to trigger ArgoCD to re-sync the whole app

ArgoCD DOES NOT depend on the CI pushing all files

It depends on the Git folder defined in the Application.

ğŸ¯ Conclusion
âœ” Break into multiple workflows (Terraform, ArgoCD bootstrap, App CI)
âœ” Reuse workflows to avoid duplication
âœ” Let Terraform handle infra, ArgoCD handle deploys, CI handle images
âœ” ArgoCD will deploy the full app even if CI updates only one file


1. The EKS Infra Workflow Should Not Auto-Trigger During This Test

Your goal: Run everything from Terraform only â†’ Argo fully deployed â†’ Argo UI visible â†’ App of Apps works.

Make sure:

on:
  push:
    paths:
      - "terraform/**"


means:

âœ” Only pushes to the terraform folder trigger infra
âœ” NOT pushing anything to terraform during your test
âœ” You will manually run Terraform on your laptop / CloudShell

This is correct for your scenario.

2. Terraform Must Includes ALL Add-Ons

Check that Terraform provisions:

Component	Installed via Terraform?
VPC	âœ”
EKS Cluster	âœ”
Node Groups	âœ”
ALB Controller	âœ”
EBS CSI Driver	âœ”
ArgoCD	âœ”
Prometheus + Grafana	(Optional but recommended)

If ArgoCD is installed via Terraform Helm Release, you are good.

3. ArgoCD Bootstrap (App of Apps) Must Already Be Declared in Terraform

In Terraform, something like:

resource "helm_release" "argocd" {
  ...
}

resource "kubernetes_manifest" "argocd_root_app" {
  manifest = yamldecode(file("${path.module}/bootstrap/root-app.yaml"))
}


Or if you install ArgoCD only, and App of Apps is applied manually later, thatâ€™s still fine.

Your goal: Argo should automatically create your applications after Terraform finishes.

4. GitOps Repo Must Already Contain the App of Apps structure

Example:

k8s/
  bootstrap/
    root-app.yaml
  apps/
    dev/
      api/
        deployment.yaml
      web/
        deployment.yaml
      mongo/
        deployment.yaml


ArgoCD must be pointed at this repo + folder.

5. Your CI/CD Workflows Should Not Break the First Deploy

On first deploy:

ArgoCD will use the image already in manifest â†’ even if itâ€™s mongo:5.0 or node:latest.

Your CI/CD will only patch images after someone edits the Dockerfile or code.

Image scanning & push flows do NOT affect first-time deployment.

This is correct.

6. Ensure OIDC Authentication for GitHub â†’ AWS is Correct

Make sure IAM role trust policy includes:

GitHub OIDC provider

repo:<owner>/<repo>:ref:refs/heads/main

This ensures CI workflows will work later.

But it does not affect Terraform apply (youâ€™re using access keys for Terraform).

ğŸ‰ If all the above are correct â†’ YES, you can run terraform apply now

What will happen in sequence:

Step 1 â€” Terraform apply

EKS created

Add-ons installed

ArgoCD installed

ArgoCD Bootstrap (App of Apps) applied

Step 2 â€” Terraform finishes

No further CI invoked

Step 3 â€” ArgoCD starts reconciliation

Argo will:

âœ” Connect to your Git repo
âœ” Read your bootstrap root-app.yaml
âœ” Create child apps
âœ” Deploy all microservices
âœ” Create ALB ingress
âœ” Expose Argo UI
âœ” You copy Argo admin password
âœ” Login to ArgoCD UI
âœ” See all apps synced


Meaning of @main

In GitHub Actions, when you call a reusable workflow:

uses: org/repo/.github/workflows/docker-reusable.yml@main


ğŸ‘‰ @main tells GitHub which version (branch, tag, or commit) of that workflow file to use.

It works exactly like this:

@main â†’ use the file from the main branch

@v1 â†’ use a release tag

@a1b2c3d â†’ use a specific commit SHA

So GitHub downloads the workflow file from that branch/tag and executes it.

ğŸ” Why do we normally use @main?

Because your reusable workflow sits in the repoâ€™s default branch (usually main).

Any time you update that reusable file on main, callers automatically get the latest version â€” unless they hard-pin versions (which is safer for production).

ğŸ” What are safer alternatives?

For stability (especially production CI/CD), itâ€™s better to reference:

âœ” A git tag
âœ” Or a specific commit SHA

Example using tag:

uses: org/repo/.github/workflows/docker-reusable.yml@v1.0.0


This ensures:

pipelines donâ€™t break unexpectedly

upgrades happen intentionally, via version bump

ğŸ”¹ Summary
Syntax	Meaning
@main	Pull reusable workflow file from the main branch
@v1	Pull from a tagged version
@commitSHA	Locked to one version

So @main is simply the version pointer of the reusable workflow youâ€™re importing.


Code + Dockerfile â†’ Build â†’ Image â†’ Deploy

auto-merge PR on approval
âœ¨ ChatOps approval with Slack
âœ¨ support Helm values.yaml update
âœ¨ multi-service update per PR

If you want next:

ğŸ”¥ automatic PR reviewers
ğŸ”¥ link PR to Jira
ğŸ”¥ auto-close PR if deployment fails
ğŸ”¥ ability to batch multiple image updates into PR


# how the web-app-ci.yml workflow is triggered
Great setup ğŸ‘ â€” what youâ€™ve built is actually a clean, realistic GitOps + CI/CD workflow chain.
The confusion youâ€™re hitting is very common, so letâ€™s break it down very clearly and practically.

Big Picture: What triggers what?

You currently have two types of workflows:

ğŸŸ¢ Standalone (entry-point) workflows

These are workflows that start on their own.

deploy-infra-terraform.yml âœ…

bootstrap-argocd.yml âœ…

web-app-ci.yml â¬…ï¸ this is also an entry-point

ğŸ” Reusable workflows

These CANNOT run by themselves.

docker-build.yml

update-manifest.yml

Reusable workflows are like functions â€” they only run when another workflow calls them via uses:.

1ï¸âƒ£ How do I trigger docker-build.yml?

You donâ€™t trigger it directly.
It is already triggered when web-app-ci.yml runs:

jobs:
  build-and-push:
    uses: ./.github/workflows/docker-build.yml


âœ… That means:

Whenever web-app-ci.yml runs

â†’ docker-build.yml is executed automatically

There is no button, no push, no manual trigger for this file.

2ï¸âƒ£ How do I trigger update-manifest.yml?

Same idea: you never trigger it directly.

It runs only when:

jobs:
  update-manifest:
    needs: build-and-push
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.deploy == 'true'
    uses: ./.github/workflows/update-manifest.yml


So it runs only if ALL are true:

web-app-ci.yml was started manually

You selected deploy = true

docker-build.yml succeeded

3ï¸âƒ£ How do I trigger web-app-ci.yml? (THIS is the key)

You have two ways.

âœ… Option A: Push-based trigger (automatic CI)
on:
  push:
    paths:
      - "k8s/apps/web-app/**"


ğŸ“Œ This triggers when you:

git add k8s/apps/web-app
git commit -m "Update web app config"
git push


What happens:

Push â†’ web-app-ci.yml
      â†’ docker-build.yml
      â†’ (NO manifest update)


Because:

workflow_dispatch was NOT used

deploy input does not exist

update-manifest job is skipped

âœ… This is pure CI (build + scan + push image)

âœ… Option B: Manual trigger (CI + GitOps deploy)

This is the full pipeline.

Steps in GitHub UI

Go to Actions

Click Web App CI

Click Run workflow

Choose:

deploy = true


Click Run

What happens:

Manual Run â†’ docker-build.yml
           â†’ update-manifest.yml
           â†’ PR created
           â†’ ArgoCD syncs after merge


ğŸ”¥ This is proper GitOps.

4ï¸âƒ£ Execution Flow (End-to-End)
ğŸŸ¦ CI only (push-based)
Push to k8s/apps/web-app/*
â†’ web-app-ci.yml
  â†’ docker-build.yml
  â†’ Image pushed to ECR

ğŸŸ© CI + GitOps deploy (manual)
Manual Run (deploy=true)
â†’ docker-build.yml
â†’ update-manifest.yml
â†’ Pull Request
â†’ Merge PR
â†’ ArgoCD syncs to cluster

5ï¸âƒ£ Why this design is GOOD (you did this right)

âœ” Reusable workflows = DRY
âœ” Manual deploy gate = SAFE
âœ” PR-based manifest update = GitOps best practice
âœ” ArgoCD remains source-of-truth
âœ” No direct cluster access from CI

This is exactly how production pipelines are built.

6ï¸âƒ£ Common Mistake (you avoided it)

âŒ Trying to trigger reusable workflows directly
âŒ Letting CI auto-deploy on every push
âŒ Editing manifests inside the same job that builds images

You avoided all three ğŸ‘

7ï¸âƒ£ One Optional Improvement (FYI)

You might later want:

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - "k8s/apps/web-app/**"


So feature branches donâ€™t trigger builds â€” but thatâ€™s optional.

Final Summary
Workflow	How it runs
deploy-infra-terraform.yml	Push / manual
bootstrap-argocd.yml	After infra
web-app-ci.yml	Push OR Manual
docker-build.yml	Only via web-app-ci.yml
update-manifest.yml	Only via web-app-ci.yml (manual + deploy=true)

# will add these later

environment protection rules

promotion (dev â†’ staging â†’ prod)

Wire Slack notifications

  image tag immutability / rollback strategy